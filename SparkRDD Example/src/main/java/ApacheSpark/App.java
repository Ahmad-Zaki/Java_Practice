package ApacheSpark;

import java.util.Arrays;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

import org.apache.commons.lang3.StringUtils;
import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

public class App 

{
	private static final String DELIMITER =",";
    public static void main( String[] args )
    {
    	//omit the log generated by apache spark from the output.
    	Logger.getLogger ("org").setLevel (Level.ERROR);
    	
    	//Create the configuration of the sparkContext object:
    	//"setMaster" method defines whether we work on a cluster of machines or on a local machine.
    	//3 denotes the number of cores used by spark to process operations.
        SparkConf configuration = new SparkConf().setAppName("Popular word title").setMaster("local[3]");
        
        // create a sparkContext object with the configuration we created:
        //The purpose of SparkContext is to coordinate the spark applications, running as independent sets of processes on each cluster "or each core in case of a local machine".
        JavaSparkContext sparkContext = new JavaSparkContext(configuration);
        
        //Read the data from file:
        JavaRDD<String> dataset = sparkContext.textFile("src\\main\\resources\\data\\USvideos.csv");
        //View some lines from the dataset:
//        int i=0;
//        for(String line:dataset.collect()){
//        	if (i<3) {
//        		System.out.println("* "+line);
//        	}
//            i++;
//        }
        
        //get the title of each video:
        //"getTitle" method is a static method we defined below.
        //we will change all letters to lowercase and trim extra spaces and remove punctuation.
        //the filter method is used to get non-empty strings only "any Null values will be filtered out".
        JavaRDD<String> titles = dataset.map(entry -> getTitle(entry).toLowerCase().trim().replaceAll("\\p{Punct}", ""))
        								.filter(entry -> StringUtils.isNotBlank(entry));
        
        //split the title to words:
        //the "flatMap" method works with lists of object, the "map" method works with objects directly.
        //we use flatMap to get the elements of the list and apply the mapping on them.
        //the "flatMap" takes an iterator of the list in order to access the elements.
        //we use "Array.asList" because the "split" method returns an array, so we change it to a list and get an iterator of that list.
        JavaRDD<String> words = titles.flatMap(title -> Arrays.asList(title.split(" ")).iterator())
        							  .filter(word -> StringUtils.isNotBlank(word)); //remove empty Strings after spliting
        
        //Count all words and map each word with its count:
        //this method returns a map<String, Long>
        Map<String, Long> wordCount = words.countByValue();
        
        //Sort the words by their count:
        //we use a stream on the entry set of wordCount map.
        //the entry set of a map is a set of every key-value pair in the map
        //the method "comparingByValue" will sort all entries based on their values.
        List<Map.Entry> sorted = wordCount.entrySet().stream()
        											 .sorted(Map.Entry.comparingByValue())
        											 .collect(Collectors.toList ());
        //Print each word and its count:
        sorted.forEach(entry ->System.out.println(entry.getKey() + ":"+ entry.getValue()));
        
        //Close the Spark context to release the system resources.
        sparkContext.close();
    }
    
    
    public static String getTitle(String entryLine) {
    	//Each line represents one data point in the dataset, the 3rd column has the title.
    	try {
    		//Split the line on the delimiter and return the 3rd value:
    		return entryLine.split(DELIMITER)[2];
    	} catch (ArrayIndexOutOfBoundsException e) {
    		//if the entry is empty, return "":
    		return ""; }
    	
    }
}
